---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
## initiate!
set.seed(413)
StudentsPerformance <- read.csv("StudentsPerformance.csv")
summary(StudentsPerformance)
```


```{r}
##Q1:
## Mjob, Fjob
str(StudentsPerformance$Fjob)
```


```{r}
str(StudentsPerformance$Mjob)
```


```{r}
##a.
n = length(StudentsPerformance$Fjob)
first_var_prop = sum(StudentsPerformance$Fjob == "at_home") / n
second_var_prop = sum(StudentsPerformance$Mjob == "at_home") / n

print(first_var_prop)
print((1 - first_var_prop))

print(second_var_prop * n)
print((1 - second_var_prop) * n)
```


```{r}
first_term = (first_var_prop * (1 - first_var_prop)) / n 
second_term = (second_var_prop * (1 - second_var_prop)) / n 
se = sqrt(first_term + second_term) 
se
```


```{r}
z_star = qnorm((1 - 0.95) / 2, lower.tail=FALSE) 
me = z_star * se 
me
```


```{r}
diff = (first_var_prop - second_var_prop) 
diff
```


```{r}
ci = c(diff - me, diff + me)
ci
```


```{r}
##b.
vs_table <- table(StudentsPerformance$Fjob, StudentsPerformance$Mjob)
vs_table
```


```{r}
chisq.test(vs_table)
##rejecect H0: there's a relation between them (??)
```


```{r}
##Q2:

rows = sample(1:nrow(StudentsPerformance), 10) 
q2_sample = StudentsPerformance[rows, ]["sex"] 
q2_sample
```


```{r}
p_hat = sum(q2_sample$sex == "M") / 10 
p_hat
```


```{r}
sample_h_0 = c(rep(1, 5), rep(0, 5))
bootstrap_populations <- replicate(1000,sample(sample_h_0, size = 10, replace = TRUE))
proportions = colSums(bootstrap_populations) / 10
p_value = sum(proportions <= 0.2) / 1000
p_value

##kinda 0.5, we cannot reject
```




```{r}
## Q3:
#a.
table(StudentsPerformance$Fjob) / n
```


```{r}
sample_size = 100
rows = sample(1:nrow(StudentsPerformance), sample_size) 
q3_unbiased_sample = StudentsPerformance[rows, ]["Fjob"] 
q3_unbiased_sample.freq = table(q3_unbiased_sample$Fjob) 
q3_unbiased_sample.freq / sample_size
table(q3_unbiased_sample$Fjob)
```


```{r}
prb <- ifelse(StudentsPerformance$Fjob=="at_home", 0.8, 0.2) 
rows <- sample(nrow(StudentsPerformance), sample_size, prob = prb) 
q3_biased_sample <- StudentsPerformance[rows, ]["Fjob"] 
q3_biased_sample.freq = table(q3_biased_sample$Fjob) 
q3_biased_sample.freq / sample_size
table(q3_biased_sample$Fjob)
```


```{r}
expected = table(StudentsPerformance$Fjob) / n
expected
```


```{r}
chisq.test(q3_unbiased_sample.freq, p=expected)
```


```{r}
chisq.test(q3_biased_sample.freq, p=expected)
```


```{r}
#b.
first_vs_second <- table(StudentsPerformance$Fjob, StudentsPerformance$Mjob) 
first_vs_second

chisq.test(first_vs_second)
```


```{r}
## Q4:
#B-a:
study_effect = lm(G3 ~ studytime, data = StudentsPerformance)
summary(study_effect)
```


```{r}
age_effect = lm(G3 ~ age, data = StudentsPerformance)
summary(age_effect)
```


```{r}
##B-c:
library(ggplot2)
ds <- data.frame(data = StudentsPerformance$age, Linear = StudentsPerformance$G3)
p <- ggplot(ds, aes(x = data)) +
geom_point(aes(y = Linear, color = "Linear"), size = 2) + stat_smooth(aes(x = data, y = Linear, linetype = "Linear Fit"),
method = "lm", formula = y ~ x, se = F, color = "pink") + scale_linetype_manual(name = "Fit Type", values = c(2, 2)) + ggtitle("G3 Vs. Age")
p
```


```{r}
ds <- data.frame(data = StudentsPerformance$studytime, Linear = StudentsPerformance$G3)
p <- ggplot(ds, aes(x = data)) +
geom_point(aes(y = Linear, color = "Linear"), size = 2, alpha = 0.5) + stat_smooth(aes(x = data, y = Linear, linetype = "Linear Fit"),
method = "lm", formula = y ~ x, se = F, color = "pink") +  scale_linetype_manual(name = "Fit Type", values = c(2, 2)) + ggtitle("G3 Vs. studytime")
p
```


```{r}
#D:
lm_q4 = lm(G3 ~ age + studytime, data = StudentsPerformance)
summary(lm_q4)
```


```{r}
anova_test = anova(lm_q4)
anova_test
```


```{r}
sse_sst = (anova_test["Residuals", "Sum Sq"] / (anova_test["Residuals", "Sum Sq"] + anova_test["studytime", "Sum Sq"] + anova_test["age", "Sum Sq"]))
r_2_adjusted = 1 - sse_sst * ((sample_size - 1) / (sample_size - 3)) 
r_2_adjusted
```


```{r}
##f.
```


```{r}
## Q5:
#a.
library(caret)
library(dplyr)
library(GGally)
```


```{r}
useful_columns = select(StudentsPerformance,-c(G2,G1,absences,health,failures,studytime,goout,age,Fjob, Mjob,X))
dummy_one_hot = dummyVars(" ~ .", data = useful_columns)
one_hot_encoded = data.frame(predict(dummy_one_hot, newdata = StudentsPerformance))
head(one_hot_encoded)
```


```{r}
##categorial only, rest are in phase I, Fjob and Mjob are hardly relavent btw, removed!
ggpairs(one_hot_encoded, title="Correlogram of StudentsPerformance")

```

```{r}
#b.

##TABLE WAS TOOOOOO COMPLICCATED! but I removed Fjob, Mjob, they're harldy relevant khodayi!
#romantic both yes/no = ±.13
#internet both yes/no = ±.114
#sex .072
#school 0.066

## nomial highets (Phase I):
## G1 and G2 are soooooooooo imp!
# age .2
# goout .14
#studytime .13
#failures .5
##  pick failures,age, goout, studytime, romantic, internet



library(ggcorrplot)
ggcorrplot(cor(one_hot_encoded), hc.order = TRUE, type = "lower", lab = TRUE)


```


```{r}
#C.
#failures+age+goout+studytime+ romantic+internet+sex  
##TABLE WAS TOOOOOO COMPLICCATED! but I removed Fjob, Mjob, they're harldy relevant khodayi!
#romantic both yes/no = ±.13
#internet both yes/no = ±.114
#sex .072
#school 0.066
## Fjob 0.01 and Mjob 0.03 both trivial
## nomial highets (Phase I):
## G1 and G2 are soooooooooo imp!
# age .2
# goout .14
#studytime .13
#failures .5
##  pick failures,age, goout, studytime, romantic, internet


final_lm_b = lm(G3 ~ G2+failures+age+romantic+goout, data = StudentsPerformance)
summary(final_lm)

#85.89% is explained

```


```{r}
#D.

train_i <- sample(1:nrow(StudentsPerformance), 0.8 * nrow(StudentsPerformance))
test_i <- setdiff(1:nrow(StudentsPerformance), train_i)
X_train <- select(StudentsPerformance,-c(X))
X_test <- select(StudentsPerformance,-c(X))
y_test <- StudentsPerformance[test_i, "G3"]
trained_lm_d = lm(G3 ~ G2+failures+age+romantic+goout , data = X_train)
RSS <- c(crossprod(trained_lm_d$residuals))
MSE <- RSS / length(trained_lm_d$residuals)
RMSE <- sqrt(MSE)
RMSE
```


```{r}
## differs bc of overfitting
predicted <- predict(trained_lm_d, X_test)
RMSE_Test = sqrt(mean((y_test - predicted)^2))
RMSE_Test

```


```{r}
#E.
school_lm = lm(G3 ~ school , data = StudentsPerformance) 
summary(school_lm)
```


```{r}
sex_lm = lm(G3 ~ sex , data = StudentsPerformance) 
summary(sex_lm)
```


```{r}
age_lm = lm(G3 ~ age , data = StudentsPerformance) 
summary(age_lm)
```


```{r}
Fjob_lm = lm(G3 ~ Fjob , data = StudentsPerformance) 
summary(Fjob_lm)
```


```{r}
Mjob_lm = lm(G3 ~ Fjob , data = StudentsPerformance) 
summary(Mjob_lm)
```


```{r}
romantic_lm = lm(G3 ~ romantic , data = StudentsPerformance) 
summary(romantic_lm)
```


```{r}
studytime_lm = lm(G3 ~ studytime , data = StudentsPerformance) 
summary(studytime_lm)
```


```{r}
failures_lm = lm(G3 ~ failures , data = StudentsPerformance) 
summary(failures_lm)
```


```{r}
health_lm = lm(G3 ~ health , data = StudentsPerformance) 
summary(health_lm)
```


```{r}
abcenses_lm = lm(G3 ~ absences , data = StudentsPerformance) 
summary(abcenses_lm)
```


```{r}
##failure has the highest value as expected, following by age, romantic and studytime
## now we should take a look at the + of features, if we pick failure.

## two features:
## .3341 for failures, .3399 for comb w age
## 0.3383 for comb with romantic
##.3333 for comb w studytime
## .342 for comb w sex
## .3337 for comb w absences
##.3334 for comb w health
##.3344 for comb w Fjob and
##.3531 for comb w Mjob
## .3334 for comb w school
two_feat = lm(G3 ~ failures+age , data = StudentsPerformance) 
summary(two_feat)
## thus, we'll choose Fjob.
## keep going 'til it's enough :D
```




```{r}
##F.
## i should firstly find features of prev. part

final_lm = lm(G3 ~ failures+age,data = StudentsPerformance)
```


```{r}
data <- data.frame( age=StudentsPerformance$age,residuals=final_lm$residuals)
ggplot(data = data,aes(age, residuals)) + geom_point() +stat_smooth(method = lm)
```


```{r}
data <- data.frame(failures=StudentsPerformance$failures, residuals=final_lm$residuals)
ggplot(data = data,aes(failures, residuals)) +geom_point() + stat_smooth(method = lm)
```


```{r}
p <- ggplot(data=final_lm,aes(final_lm$residuals)) + geom_histogram(bins=20, fill="pink2")
 
p
```


```{r}
ggplot(final_lm,aes(sample=final_lm$residuals)) +stat_qq(col="purple") +stat_qq_line()
```


```{r}
ks.test(unique(final_lm$residuals), "pnorm", mean=0, sd=1)
```


```{r}
ggplot(data = final_lm,aes(final_lm$fitted,final_lm$residuals)) + geom_point() + stat_smooth(method = lm)
```


```{r}
## G.
## i should firstly find features of prev. part
cv_model <- train(G3 ~ failures+age , data=StudentsPerformance, trControl=trainControl(method="cv", number=5),method="lm")
cv_model
```


```{r}
## Q6:
#a.
##randomly chosen!

sex_Data  = as.integer(StudentsPerformance$sex == "F") 

q6_glm = glm(sex_Data ~ studytime+school+G1+romantic , family= binomial,  data = StudentsPerformance)
summary(q6_glm)
```


```{r}
#b.

```


```{r}
#c.
library(pROC)
lm_q6p = data.frame(StudentsPerformance)
q6_glm = glm(sex_Data ~ studytime+school+G1+romantic,family = binomial, data = lm_q6p)
prob = predict(q6_glm, type=c("response"))


roc_curve = roc(sex_Data ~ prob,data = lm_q6p,percent=TRUE,
    #Area under curve
    partial.auc=c(100, 90),
    partial.auc.correct=TRUE,
    partial.auc.focus="sens",
    
    #CI
    ci=TRUE,
    boot.n=100,
    ci.alpha=0.95,
    stratified=FALSE,
    
    # Plot
    plot=TRUE,
    auc.polygon=TRUE,
    max.auc.polygon=TRUE,
    grid=TRUE,
    print.auc=TRUE,
    show.thres=TRUE)

```


```{r}
#e.



```


